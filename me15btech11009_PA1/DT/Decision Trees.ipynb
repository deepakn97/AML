{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implementing decision tree\n",
    "class Decisiontree():\n",
    "    def __init__(self):\n",
    "        import numpy\n",
    "        import csv\n",
    "        self.np = numpy\n",
    "        self.csv = csv\n",
    "        self.is_continous = [1,0,1,0,1,0,0,0,0,0,1,1,1,0]\n",
    "        self.values_num = [] #number of values under given attribute\n",
    "        self.discrete = {1:['Private', 'Self-emp-not-inc', 'Self-emp-inc', 'Federal-gov', 'Local-gov', 'State-gov', 'Without-pay', 'Never-worked'],\n",
    "         3:['Bachelors', 'Some-college', '11th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc', '9th', '7th-8th', '12th', 'Masters', '1st-4th', '10th', 'Doctorate', '5th-6th', 'Preschool'],\n",
    "        5:['Married-civ-spouse', 'Divorced', 'Never-married', 'Separated', 'Widowed', 'Married-spouse-absent', 'Married-AF-spouse'],\n",
    "        6:['Tech-support', 'Craft-repair', 'Other-service', 'Sales', 'Exec-managerial', 'Prof-specialty', 'Handlers-cleaners', 'Machine-op-inspct', 'Adm-clerical', 'Farming-fishing', 'Transport-moving', 'Priv-house-serv', 'Protective-serv', 'Armed-Forces'],\n",
    "        7:['Wife', 'Own-child', 'Husband', 'Not-in-family', 'Other-relative', 'Unmarried'],\n",
    "        8:['White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black'],\n",
    "        9:['Male', 'Female'],\n",
    "        13:['United-States', 'Cambodia', 'England', 'Puerto-Rico', 'Canada', 'Germany', 'Outlying-US(Guam-USVI-etc)', 'India', 'Japan', 'Greece', 'South', 'China', 'Cuba', 'Iran', 'Honduras', 'Philippines', 'Italy', 'Poland', 'Jamaica', 'Vietnam', 'Mexico', 'Portugal', 'Ireland', 'France', 'Dominican-Republic', 'Laos', 'Ecuador', 'Taiwan', 'Haiti', 'Columbia', 'Hungary', 'Guatemala', 'Nicaragua', 'Scotland', 'Thailand', 'Yugoslavia', 'El-Salvador', 'Trinadad&Tobago', 'Peru', 'Hong', 'Holand-Netherlands'],\n",
    "        14:['0','1']}\n",
    "        self.partitions = {}\n",
    "        self.tree = {}\n",
    "    \n",
    "    def most_frequent(self,data,attr):\n",
    "        #gets the most frequent value in an attribute\n",
    "        if(len(data)==0):\n",
    "            return self.np.random.randint(2)\n",
    "            \n",
    "        max_val = 0\n",
    "        temp_data = self.np.array(data)\n",
    "        best_value = None\n",
    "        for value in self.discrete[int(attr)]:\n",
    "            cnt = self.np.array(temp_data)[:,int(attr)].ravel().tolist().count(value)\n",
    "            if(cnt > max_val):  \n",
    "                max_val = cnt\n",
    "                best_value = value\n",
    "        return best_value\n",
    "        \n",
    "    def discretize(self,data,attr):\n",
    "        \n",
    "        #discretize/convert in bins, all the continous data\n",
    "        for record in data:\n",
    "            if(record[attr] == '?'):\n",
    "                continue\n",
    "            c = int(record[attr])\n",
    "            m,min_val,max_val = self.partitions[attr]\n",
    "            if(c < m):\n",
    "                record[attr] = '0'\n",
    "            elif(c < 2*m):\n",
    "                record[attr] = '1'\n",
    "            elif(c < 3*m):\n",
    "                record[attr] = '2'\n",
    "            elif(c<4*m):\n",
    "                record[attr] = '3'\n",
    "            else:\n",
    "                record[attr] = '4'\n",
    "        return data\n",
    "            \n",
    "    def partition(self, data, attr):        \n",
    "        #getting all the values belonging to that attribute\n",
    "        temp = self.np.array(data[:,attr]).ravel()\n",
    "        temp = [int(t) for t in temp]\n",
    "        \n",
    "        #getting range for deciding partition size\n",
    "        max_val = 0\n",
    "        min_val = 1000000000\n",
    "        \n",
    "        for num in temp:\n",
    "            if(num < min_val):\n",
    "                min_val = num\n",
    "            if(num > max_val):\n",
    "                max_val = num\n",
    "        m = (max_val-min_val)/5\n",
    "        self.partitions[attr] = [m,min_val,max_val]\n",
    "        \n",
    "        self.discrete[attr] = ['0','1','2','3','4']\n",
    "        self.discretize(data,attr)\n",
    "        return data\n",
    "    \n",
    "    def handle_exceptions(self,data):\n",
    "        #assign most frequent value in that attribute for invalid values\n",
    "        for record in data:\n",
    "            for i in range(len(record)):\n",
    "                if(record[i] == '?'):\n",
    "#                     record[i] = self.most_frequent(data,i)\n",
    "                    record[i] = str(self.discrete[i][self.np.random.randint(self.values_num[i])])\n",
    "        return data\n",
    "    \n",
    "    def process_train_data(self, data):\n",
    "        \n",
    "        final_data = data[:]\n",
    "        for i in range(len(final_data[1,:-1])):\n",
    "            if(self.is_continous[i]==1):\n",
    "                final_data = self.partition(final_data, i)\n",
    "            self.values_num.append(len(self.discrete[i]))\n",
    "        final_data = self.handle_exceptions(final_data) \n",
    "        return final_data\n",
    "    \n",
    "    def process_test_data(self,data):\n",
    "        final_data = data[:]\n",
    "        for i in range(len(final_data[1,:-1])):\n",
    "            if(self.is_continous[i] == 1):\n",
    "                final_data = self.discretize(final_data,i)\n",
    "        final_data = self.handle_exceptions(final_data)\n",
    "        return final_data\n",
    "    \n",
    "    def clean_data(self,data,string):\n",
    "        final_data = data[:]\n",
    "        if(string == \"train\"):\n",
    "            final_data = self.process_train_data(final_data)\n",
    "        else:\n",
    "            final_data = self.process_test_data(final_data)\n",
    "        return final_data\n",
    "    \n",
    "    #get entropy\n",
    "    def get_records(self, data, attr, value):\n",
    "        \n",
    "        #gets all the examples which have value as attr attribute value\n",
    "        temp_data = data[:]\n",
    "        final_records = [record for record in temp_data if record[int(attr)]==value]\n",
    "        return final_records\n",
    "    \n",
    "    def get_entropy(self, data):\n",
    "        \n",
    "        #get enrtropy of whole data\n",
    "        temp_data = data[:]\n",
    "        entropy = 0.0\n",
    "        labels_count = [0,0]\n",
    "        \n",
    "        labels_count[0] = self.np.array(temp_data)[:,len(temp_data[0])-1].ravel().tolist().count('0')\n",
    "        labels_count[1] = self.np.array(temp_data)[:,len(temp_data[0])-1].ravel().tolist().count('1')\n",
    "        \n",
    "        for i in range(2):\n",
    "            if(labels_count[i]==0):\n",
    "                continue\n",
    "            entropy += ((-1.0*float(labels_count[i])/float(len(data)))*(self.np.log2(float(labels_count[i])) - self.np.log2(float(len(data)))))\n",
    "        return entropy\n",
    "    \n",
    "    def get_gain(self, data, attr):\n",
    "        \n",
    "        #gets gain in information if split on attr attribute\n",
    "        temp_data = data[:]\n",
    "        gain = 0.0\n",
    "        subset_entropy = 0.0\n",
    "        \n",
    "        for value in self.discrete[int(attr)]:\n",
    "            data_subset = self.get_records(temp_data, attr, value)\n",
    "            if(len(data_subset)==0):\n",
    "                continue\n",
    "            prob = float(len(data_subset))/float(len(data))\n",
    "            subset_entropy += prob*self.get_entropy(data_subset)\n",
    "        gain = self.get_entropy(temp_data) - subset_entropy\n",
    "        return gain\n",
    "        \n",
    "        \n",
    "    def get_classification(self, record, tree):\n",
    "        \n",
    "        #recursice function to traverse the depth of tree(dfs)\n",
    "        if(type(tree) != dict):\n",
    "            return tree\n",
    "        else:\n",
    "            att = tree.keys()[0]\n",
    "            t = tree[att][record[int(att)]]\n",
    "            return self.get_classification(record, t)\n",
    "     \n",
    "    def predict(self, file_string):\n",
    "        raw_data = []\n",
    "        #read data in form of list of lists\n",
    "        with open(file_string, 'r') as f:   \n",
    "            raw = self.csv.reader(f, delimiter = '\\n')           \n",
    "            for row in raw:\n",
    "                raw_data.append(row[0].split(', '))\n",
    "        \n",
    "        test_data = self.clean_data(self.np.array(raw_data),\"test\")\n",
    "        temp_data = test_data[:]\n",
    "        \n",
    "        classification = []\n",
    "        for record in temp_data:\n",
    "            classification.append(self.get_classification(record,self.tree))\n",
    "        \n",
    "        return classification\n",
    "    \n",
    "    def next_best(self,attributes,data):\n",
    "        \n",
    "        #selecting next best attribute for splitting\n",
    "        best_gain = 0.0\n",
    "        best_attribute = None\n",
    "        \n",
    "        for attr in attributes:\n",
    "            gain = self.get_gain(data,attr)\n",
    "            if(gain >= best_gain):\n",
    "                best_gain = gain\n",
    "                best_attribute = attr\n",
    "        return best_attribute\n",
    "        \n",
    "    def create_dtree(self ,attributes, data, depth):\n",
    "        \n",
    "        #recursive function to create decision tree\n",
    "        c_data = data[:]\n",
    "        labels = [record[len(c_data[0])-1] for record in c_data] \n",
    "        majority = self.most_frequent(data,14)\n",
    "        \n",
    "        if(len(data) == 0 or len(attributes)-1 <= 0 or depth >=10 ):\n",
    "            return majority\n",
    "        elif(len(set(labels))==1):\n",
    "            return labels[0]\n",
    "        else:\n",
    "            #getting next best attributeq\n",
    "            best_attribute = self.next_best(attributes,data)\n",
    "            #creating a new subtree for next_best_attribute\n",
    "            tree={best_attribute:{}}\n",
    "            #create a subtree for every possible value in best_attribute\n",
    "            for vals in self.discrete[int(best_attribute)]:\n",
    "                data_subset = self.get_records(c_data, best_attribute, vals)\n",
    "                attr = [attri for attri in attributes if attri != best_attribute]\n",
    "                \n",
    "                next_subtree = self.create_dtree(attr,data_subset,depth+1)\n",
    "                \n",
    "                tree[best_attribute][vals] = next_subtree\n",
    "            return tree\n",
    "        \n",
    "    def train(self, file_string):\n",
    "        raw_data = []\n",
    "        #read data in form of list of lists\n",
    "        with open(file_string, 'r') as f:   \n",
    "            raw = self.csv.reader(f, delimiter = '\\n')           \n",
    "            for row in raw:\n",
    "                raw_data.append(row[0].split(', '))\n",
    "        \n",
    "        attributes = [str(i) for i in range(14)]\n",
    "        \n",
    "        train_data = self.clean_data(self.np.array(raw_data), \"train\")\n",
    "        \n",
    "        self.tree = self.create_dtree(attributes,train_data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "model = Decisiontree()\n",
    "model.train('/home/desmond/Programming/MachineLearning/AML/PA1/DT/dataset.csv')\n",
    "with open('me15btech11009.model','w') as f:\n",
    "    dill.dump(model,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
