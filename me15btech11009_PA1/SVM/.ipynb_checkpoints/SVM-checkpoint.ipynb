{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "\n",
    "class SVM():\n",
    "        \n",
    "    def read_data(self, file_string):\n",
    "        raw_data = []\n",
    "        #read data in form of list of lists\n",
    "        with open(file_string, 'r') as f:   \n",
    "            raw = csv.reader(f, delimiter = '\\n')           \n",
    "            for row in raw:\n",
    "                raw_data.append(row[0].split(', '))\n",
    "            # print(raw_data)\n",
    "        return raw_data\n",
    "\n",
    "    def __init__(self):\n",
    "            self.is_continous = [1,0,1,0,1,0,0,0,0,0,1,1,1,0]\n",
    "            self.discrete = {1:['Private', 'Self-emp-not-inc', 'Self-emp-inc', 'Federal-gov', 'Local-gov', 'State-gov', 'Without-pay', 'Never-worked'],\n",
    "             3:['Bachelors', 'Some-college', '11th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc', '9th', '7th-8th', '12th', 'Masters', '1st-4th', '10th', 'Doctorate', '5th-6th', 'Preschool'],\n",
    "            5:['Married-civ-spouse', 'Divorced', 'Never-married', 'Separated', 'Widowed', 'Married-spouse-absent', 'Married-AF-spouse'],\n",
    "            6:['Tech-support', 'Craft-repair', 'Other-service', 'Sales', 'Exec-managerial', 'Prof-specialty', 'Handlers-cleaners', 'Machine-op-inspct', 'Adm-clerical', 'Farming-fishing', 'Transport-moving', 'Priv-house-serv', 'Protective-serv', 'Armed-Forces'],\n",
    "            7:['Wife', 'Own-child', 'Husband', 'Not-in-family', 'Other-relative', 'Unmarried'],\n",
    "            8:['White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black'],\n",
    "            9:['Male', 'Female'],\n",
    "            13:['United-States', 'Cambodia', 'England', 'Puerto-Rico', 'Canada', 'Germany', 'Outlying-US(Guam-USVI-etc)', 'India', 'Japan', 'Greece', 'South', 'China', 'Cuba', 'Iran', 'Honduras', 'Philippines', 'Italy', 'Poland', 'Jamaica', 'Vietnam', 'Mexico', 'Portugal', 'Ireland', 'France', 'Dominican-Republic', 'Laos', 'Ecuador', 'Taiwan', 'Haiti', 'Columbia', 'Hungary', 'Guatemala', 'Nicaragua', 'Scotland', 'Thailand', 'Yugoslavia', 'El-Salvador', 'Trinadad&Tobago', 'Peru', 'Hong', 'Holand-Netherlands'],\n",
    "            14:['0','1']}\n",
    "            self.att_average = {}\n",
    "            self.sigma = 0.7 #fixed after analyzing accuracies for different sigmas\n",
    "            self.q = 0       #fixed after analyzing accuracies for different q\n",
    "            \n",
    "    def cls_avg(self, data, attr): \n",
    "        #function to calculate average of a particular attribute(ignoring '?' values)\n",
    "        if(attr in self.att_average.keys()):\n",
    "            return self.att_average[attr]\n",
    "        \n",
    "        final_data = data[:]\n",
    "        cls_sum = 0.0\n",
    "        for record in data:\n",
    "            if(record[attr]!='?'):\n",
    "                cls_sum += float(record[attr])\n",
    "        cls_sum = cls_sum/len(data)\n",
    "        self.att_average[attr] = cls_sum\n",
    "        return cls_sum\n",
    "         \n",
    "    def normalise(self,data):\n",
    "        final_data = data[:]\n",
    "        # print(final_data)\n",
    "        maxi = np.amax(np.array(data),axis = 0)\n",
    "        mini = np.amin(np.array(data), axis = 0)\n",
    "        \n",
    "        # mean_lst = np.mean(np.array(data), axis = 0)\n",
    "        # std_lst = np.std(np.array(data),axis = 0)\n",
    "        # use (x-mean)/std for better generalisation,will take more training time\n",
    "        \n",
    "        for record in final_data:\n",
    "            for i in range(len(final_data[0])):\n",
    "                if(i!=14):\n",
    "                    record[i] = float(record[i])/(maxi[i]-mini[i])\n",
    "        return final_data\n",
    "            \n",
    "    def change_to_continous(self, data, attr):\n",
    "        #change attribute number attr to continous and normalise\n",
    "        for record in data:\n",
    "            if(record[int(attr)]=='?'):\n",
    "                continue\n",
    "            record[int(attr)] = float(self.discrete[int(attr)].index(record[int(attr)]) + 1)/len(self.discrete[int(attr)])\n",
    "        return data\n",
    "    \n",
    "    def handle_exceptions(self,data):\n",
    "        #give average value of the attribute if the value is faulty\n",
    "        for record in data:\n",
    "            for i in range(len(record)):\n",
    "                if(record[i] == '?'):\n",
    "                    record[i] = self.cls_avg(data,i)\n",
    "        return data\n",
    "    \n",
    "    def process_data(self, data):\n",
    "        final_data = data[:]\n",
    "        r = len(final_data[0])\n",
    "        for i in range(r):\n",
    "            if(self.is_continous[i]==0):\n",
    "                final_data = self.change_to_continous(final_data, i)\n",
    "        print(\"Changed\")\n",
    "        final_data = self.handle_exceptions(final_data)\n",
    "        print(\"Handeled\")\n",
    "        \n",
    "        for record in final_data:\n",
    "            for i in range(len(record)):\n",
    "                record[i] = float(record[i])\n",
    "        \n",
    "\n",
    "        final_data = self.normalise(final_data)\n",
    "        print(\"Normalised\")\n",
    "        return final_data\n",
    "    \n",
    "    def clean_data(self,data,string):\n",
    "        final_data = data[:]\n",
    "        final_data = self.process_data(final_data)\n",
    "        return final_data\n",
    "    \n",
    "    def kernel_lin(self,X,Y):\n",
    "        return np.dot(np.array(X),np.transpose(Y))\n",
    "    \n",
    "    def kernel_pol(self,X,Y):\n",
    "        xy = np.dot(X,np.transpose(Y))\n",
    "        # print(xy)\n",
    "        xy += 1\n",
    "        # print(xy)\n",
    "        return np.power(xy,self.q)\n",
    "        \n",
    "    def kernel_gauss(self,X,Y):\n",
    "        x_x = np.zeros((X.shape[0],1))\n",
    "        y_y = np.zeros((1,Y.shape[0]))\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            x_x[i][0] = np.dot(X[i],np.transpose(X[i]))\n",
    "        \n",
    "        for i in range(Y.shape[0]):\n",
    "            y_y[0][i] = np.dot(Y[i],np.transpose(Y[i]))\n",
    "                \n",
    "        X_Y = 2*np.dot(X,np.transpose(Y))\n",
    "        \n",
    "        return np.exp((X_Y-x_x-y_y)/float((self.sigma * self.sigma)))\n",
    "    \n",
    "    def test_kernels(self, x_train, labels, k):\n",
    "        # print(self.sigma)\n",
    "        print(\"\\nLinear kernel\")\n",
    "        estimator = SVC(kernel = self.kernel_lin)\n",
    "        start = time()\n",
    "        x_train_temp = x_train\n",
    "        labels_temp = labels\n",
    "        accuracy = cross_val_score(estimator,x_train_temp,labels_temp,cv=k)\n",
    "        stop = time()\n",
    "        print(\"Time: \", stop-start, \"Accuracy: \",sum(accuracy)/5)\n",
    "    \n",
    "        print(\"\\nPolynomial kernel\")\n",
    "        estimator = SVC(kernel = self.kernel_pol)\n",
    "        for i in range(5):    \n",
    "            start = time()\n",
    "            x_train_temp = x_train\n",
    "            labels_temp = labels\n",
    "            self.q = i+1\n",
    "            accuracy = cross_val_score(estimator,x_train_temp,labels_temp,cv=k)\n",
    "            stop = time()\n",
    "            print(\"q = \", self.q, \"Time: \", stop-start, \"Accuracy: \",sum(accuracy)/5)\n",
    "\n",
    "        print(\"\\nGaussian Kernel\")\n",
    "        estimator = SVC(kernel = self.kernel_gauss)\n",
    "        for i in range(9):\n",
    "            start = time()\n",
    "            x_train_temp = x_train\n",
    "            labels_temp = labels\n",
    "            self.sigma = float(i+1)/10.0\n",
    "            accuracy = cross_val_score(estimator,x_train_temp,labels_temp,cv=k)\n",
    "            stop = time()\n",
    "            print(\"sigma = \", self.sigma, \"Time: \", stop-start, \"Accuracy: \",sum(accuracy)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiKernelfixedrules(object):\n",
    "    def __init__(self, kernels, X=None, Y = None):\n",
    "        self.kernels = kernels\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        # giving weights according to the accuracies. accuracy[kernel_method]/sum(accuracy)\n",
    "        self.w =[0.3312,0.3355,0.3332] \n",
    "        \n",
    "    def multiKernelFixed(self, X, Y): #kernel to be used\n",
    "        return sum([self.w[i] * self.kernels[i](X,Y) for i in range(3)])\n",
    "\n",
    "    def validation(self):  # Testing purposes\n",
    "        print(\"\\nMultiKernelFixed: \")\n",
    "        multi = SVC(kernel=self.multiKernelFixed)\n",
    "        start = time()\n",
    "        scores = cross_val_score(multi, self.X, self.Y, cv=5)\n",
    "        stop = time()\n",
    "        print('accuracy=', sum(scores)/5, 'time', stop-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiKernelheuristic(object):\n",
    "    def __init__(self, kernels, X=None, Y = None):\n",
    "        self.kernels = kernels\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.nm = [0,0,0]\n",
    "        self.flag = 0\n",
    "        \n",
    "    def heuristic(self,X,Y):\n",
    "        #to compute coefficients of each gram matrix obtained from seperate kernels\n",
    "        y_y= np.dot(Y,np.transpose(Y))\n",
    "        \n",
    "        for i in range(3):\n",
    "            gram = self.kernels[i](X,Y)\n",
    "            frob_k_yy = np.sum(np.multiply(gram,y_y))\n",
    "            frob_k_k = np.sum(np.multiply(gram,gram))\n",
    "            \n",
    "            self.nm[i] = frob_k_yy/(len(self.X) * np.sqrt(frob_k_k))\n",
    "        self.flag = 1\n",
    "        s = sum(self.nm)\n",
    "        self.nm = [x/s for x in self.nm]\n",
    "        \n",
    "    def multi_heuristic(self,X,Y): # kernel to be used\n",
    "        if(not self.flag):\n",
    "            self.heuristic(X,Y)\n",
    "        return sum([self.nm[i] * self.kernels[i](X,Y) for i in range(3)])\n",
    "    \n",
    "    def validation(self):\n",
    "        print(\"\\nMultiKernelheuristic: \")\n",
    "        multi = SVC(kernel=self.multi_heuristic)\n",
    "        start = time()\n",
    "        scores = cross_val_score(multi, self.X, self.Y, cv=5)\n",
    "        stop = time()\n",
    "        print('accuracy=', sum(scores)/5, 'time', stop-start)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class check_class(object):\n",
    "    def __init__(self,data,labels,s):\n",
    "        self.x_train = data\n",
    "        self.labels=labels\n",
    "        self.s = s\n",
    "    \n",
    "    def check_seperate_kernel(self):\n",
    "        x_trains_temp = self.x_train\n",
    "        labels_temp = self.labels\n",
    "        self.s.test_kernels(x_trains_temp,labels_temp,5)\n",
    "        \n",
    "    def check_multi_fixed(self):\n",
    "        x_trains_temp = self.x_train\n",
    "        labels_temp = self.labels\n",
    "        mkfr = MultiKernelfixedrules([self.s.kernel_lin,self.s.kernel_pol,self.s.kernel_gauss],x_trains_temp,labels_temp)\n",
    "        mkfr.validation()\n",
    "    \n",
    "    def check_multi_heuristic(self):\n",
    "        x_trains_temp = self.x_train\n",
    "        labels_temp = self.labels\n",
    "        mkh = MultiKernelheuristic([self.s.kernel_lin,self.s.kernel_pol,self.s.kernel_gauss],x_trains_temp,labels_temp)\n",
    "        mkh.validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed\n",
      "Handeled\n",
      "Normalised\n",
      "\n",
      "Linear kernel\n",
      "Time:  3.026012420654297 Accuracy:  0.836250183252\n",
      "\n",
      "Polynomial kernel\n",
      "q =  1 Time:  6.155317544937134 Accuracy:  0.836125261328\n",
      "q =  2 Time:  6.827847242355347 Accuracy:  0.84787526543\n",
      "q =  3 Time:  25.294585943222046 Accuracy:  0.846999718017\n",
      "q =  4 Time:  47.95439553260803 Accuracy:  0.84350034126\n",
      "q =  5 Time:  177.61670446395874 Accuracy:  0.836750730274\n",
      "\n",
      "Gaussian Kernel\n",
      "sigma =  0.1 Time:  18.25573420524597 Accuracy:  0.785622667138\n",
      "sigma =  0.2 Time:  15.058085680007935 Accuracy:  0.815996036522\n",
      "sigma =  0.3 Time:  12.446285963058472 Accuracy:  0.830624087548\n",
      "sigma =  0.4 Time:  11.7430739402771 Accuracy:  0.836499714502\n",
      "sigma =  0.5 Time:  11.401437044143677 Accuracy:  0.837499089795\n",
      "sigma =  0.6 Time:  11.013935565948486 Accuracy:  0.840375340869\n",
      "sigma =  0.7 Time:  10.880332231521606 Accuracy:  0.841375497315\n",
      "sigma =  0.8 Time:  10.83888053894043 Accuracy:  0.841251122315\n",
      "sigma =  0.9 Time:  10.82202672958374 Accuracy:  0.840876590967\n",
      "\n",
      "MultiKernelFixed: \n",
      "accuracy= 0.838749871045 time 88.71659922599792\n",
      "\n",
      "MultiKernelheuristic: \n",
      "accuracy= 0.8385000271 time 125.89539170265198\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    s = SVM()\n",
    "    raw_data = (s.read_data('/home/desmond/Programming/MachineLearning/AML/PA1/SVM/data/train.csv'))\n",
    "    \n",
    "    x_train = np.array(raw_data)[:,:-1].tolist()\n",
    "    labels = np.array(raw_data)[:,len(raw_data[0])-1].tolist()\n",
    "    data = s.process_data(x_train)\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = int(labels[i]) \n",
    "     \n",
    "    #getting time and accuracy for every method\n",
    "    check = check_class(data, labels,s)\n",
    "    check.check_seperate_kernel()\n",
    "    check.check_multi_fixed()\n",
    "    check.check_multi_heuristic()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of accuracies and training time between Linear, Polynomial and Gaussian Kernels:\n",
    "\n",
    "#### Linear-\n",
    "1. Best(only) accuracy is 83.62%.\n",
    "2. Training time is 3.02s\n",
    "\n",
    "#### Polynomial\n",
    "1. Best accuracy is reported for q = 2, and is equal to 84.78%.\n",
    "2. Training Time for q = 2 is 6.82s\n",
    "\n",
    "#### Gaussian\n",
    "1. Best accuracy is reported for sigma = 0.7, and is equal to 84.14%.\n",
    "2. Training time for sigma = 0.7 is 10.88s\n",
    "\n",
    "     As we can see from above data accrucay follows order Polynomial > Gaussian > Linear and training time follows the order Gaussian > Polynomial > Linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between MultiKernelFixedRule with Seperate kernels\n",
    "\n",
    "#### Accuracy:\n",
    "1. MultiKernelFixed rule gives accuracy of 83.87%\n",
    "2. As we can observe accuracy is lower than that of Polynomial but higher than Linear.\n",
    "\n",
    "#### Time:\n",
    "1. MultiKernelFixed rule takes 88.71s which is higher than each kernel seperate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of MultiKernelHeuristic with all other methods\n",
    "\n",
    "#### Accuracy:\n",
    "1. Accuracy is 83.85 which is comparable to MultiKernelFixedRule and lesser than Polynomial kernel.\n",
    "\n",
    "#### Time:\n",
    "1. Training Time is 125.89s which is more than every other method used"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
